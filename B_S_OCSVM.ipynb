{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDEonGFpRi8V"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Image preprocessing function\n",
        "def preprocess_image(image_path, target_size=(128, 128)):\n",
        "    image = imread(image_path)\n",
        "    image_resized = resize(image, target_size, anti_aliasing=True)\n",
        "    return image_resized.flatten()\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_and_preprocess_images(csv_data, base_path):\n",
        "    images = []\n",
        "    for path in csv_data['path']:\n",
        "        full_path = f\"{base_path}/{path}\"\n",
        "        image = preprocess_image(full_path)\n",
        "        images.append(image)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load the CSV files\n",
        "subhashree_csv_path = '/content/drive/MyDrive/DatasetFile-augmented-subhashree.csv'\n",
        "bahubali_csv_path = '/content/drive/MyDrive/DatasetFile-augmented-bahubali.csv'\n",
        "\n",
        "# Read the CSV files\n",
        "subhashree_data = pd.read_csv(subhashree_csv_path)\n",
        "bahubali_data = pd.read_csv(bahubali_csv_path)\n",
        "\n",
        "# Define base paths (update the base path to your actual path)\n",
        "base_path = '/content/drive/MyDrive/'  # Update this to your actual base path if different\n",
        "\n",
        "# Preprocess subhashree and bahubali images\n",
        "subhashree_images = load_and_preprocess_images(subhashree_data, base_path)\n",
        "bahubali_images = load_and_preprocess_images(bahubali_data, base_path)\n",
        "\n",
        "# Split subhashree images into training and testing sets (80% train, 20% test)\n",
        "train_images, test_images = train_test_split(subhashree_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Combine test images of subhashree and bahubali for testing\n",
        "combined_test_images = np.vstack((test_images, bahubali_images))\n",
        "\n",
        "# Define the true labels\n",
        "true_labels = np.array([1] * len(test_images) + [0] * len(bahubali_images))\n",
        "print(len(true_labels))\n",
        "# Train the One-Class SVM with the best parameters\n",
        "best_nu = 0.1\n",
        "best_gamma = 0.01\n",
        "kernel = 'rbf'\n",
        "\n",
        "ocsvm = OneClassSVM(nu=best_nu, gamma=best_gamma)\n",
        "ocsvm.fit(train_images)\n",
        "\n",
        "# Make predictions on the combined test set\n",
        "predictions = ocsvm.predict(combined_test_images)\n",
        "\n",
        "# Convert predictions to binary labels (1 for inliers, 0 for outliers)\n",
        "binary_predictions = (predictions == 1).astype(int)\n",
        "print(len(binary_predictions))\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(true_labels, binary_predictions)\n",
        "conf_matrix = confusion_matrix(true_labels, binary_predictions)\n",
        "class_report = classification_report(true_labels, binary_predictions)\n",
        "\n",
        "print(\"Final Model Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ],
      "metadata": {
        "id": "tPPKUux2RnAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Image preprocessing function\n",
        "def preprocess_image(image_path, target_size=(128, 128)):\n",
        "    image = imread(image_path)\n",
        "    image_resized = resize(image, target_size, anti_aliasing=True)\n",
        "    return image_resized.flatten()\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_and_preprocess_images(csv_data, base_path):\n",
        "    images = []\n",
        "    for path in csv_data['path']:\n",
        "        full_path = f\"{base_path}/{path}\"\n",
        "        image = preprocess_image(full_path)\n",
        "        images.append(image)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load the CSV files\n",
        "subhashree_csv_path = '/content/drive/MyDrive/DatasetFile-augmented-subhashree.csv'\n",
        "bahubali_csv_path = '/content/drive/MyDrive/DatasetFile-augmented-bahubali.csv'\n",
        "\n",
        "# Read the CSV files\n",
        "subhashree_data = pd.read_csv(subhashree_csv_path)\n",
        "bahubali_data = pd.read_csv(bahubali_csv_path)\n",
        "\n",
        "# Define base paths (update the base path to your actual path)\n",
        "base_path = '/content/drive/MyDrive/'  # Update this to your actual base path if different\n",
        "\n",
        "# Preprocess subhashree and bahubali images\n",
        "subhashree_images = load_and_preprocess_images(subhashree_data, base_path)\n",
        "bahubali_images = load_and_preprocess_images(bahubali_data, base_path)\n",
        "\n",
        "# Apply PCA to reduce dimensionality while retaining 99% variance\n",
        "pca = PCA(n_components=0.55, svd_solver='full')\n",
        "subhashree_images_pca = pca.fit_transform(subhashree_images)\n",
        "bahubali_images_pca = pca.transform(bahubali_images)\n",
        "\n",
        "# Split subhashree images into training and testing sets (80% train, 20% test)\n",
        "train_images, test_images = train_test_split(subhashree_images_pca, test_size=0.2, random_state=42)\n",
        "\n",
        "# Combine test images of subhashree and bahubali for testing\n",
        "combined_test_images = np.vstack((test_images, bahubali_images_pca))\n",
        "\n",
        "# Define the true labels\n",
        "true_labels = np.array([1] * len(test_images) + [0] * len(bahubali_images))\n",
        "print(len(true_labels))\n",
        "\n",
        "# Train the One-Class SVM with the best parameters\n",
        "best_nu = 0.1\n",
        "best_gamma = 0.01\n",
        "\n",
        "ocsvm = OneClassSVM(nu=best_nu, gamma=best_gamma)\n",
        "ocsvm.fit(train_images)\n",
        "\n",
        "# Make predictions on the combined test set\n",
        "predictions = ocsvm.predict(combined_test_images)\n",
        "\n",
        "# Convert predictions to binary labels (1 for inliers, 0 for outliers)\n",
        "binary_predictions = (predictions == 1).astype(int)\n",
        "print(len(binary_predictions))\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(true_labels, binary_predictions)\n",
        "conf_matrix = confusion_matrix(true_labels, binary_predictions)\n",
        "class_report = classification_report(true_labels, binary_predictions)\n",
        "\n",
        "print(\"Final Model Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# Print all predictions of the combined dataset\n",
        "print(\"Predictions on combined dataset:\\n\", binary_predictions)\n"
      ],
      "metadata": {
        "id": "Ldw2kx_dR4xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize PCA components\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(subhashree_images_pca[:, 0], subhashree_images_pca[:, 1], label='Subhashree', alpha=0.5)\n",
        "plt.scatter(bahubali_images_pca[:, 0], bahubali_images_pca[:, 1], label='Bahubali', alpha=0.5)\n",
        "plt.title('PCA Components Visualization')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yUG6sTiKR5z-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}